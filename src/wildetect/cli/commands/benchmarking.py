import logging
from pathlib import Path

import typer
import yaml

# from ...core.config_loader import ConfigLoader
from ...core.config_models import BenchmarkConfigModel
from ...utils.benchmark import BenchmarkPipeline

# Configure logging
logger = logging.getLogger(__name__)

app = typer.Typer(name="benchmarking", help="Benchmarking commands for WildDetect")


@app.command()
def detection(
    config: str = typer.Option(
        ..., "-c", "--config", help="Path to benchmark configuration file"
    ),
):
    """
    Run detection pipeline benchmarking with hyperparameter optimization.

    This command will:
    1. Load the benchmark configuration from the specified YAML file
    2. Find test images in the configured directory
    3. Run Optuna optimization to find the best hyperparameters
    4. Save results and optionally generate performance plots

    Example:
        wildetect benchmarking detection --config config/benchmark.yaml
        wildetect benchmarking detection --config config/benchmark.yaml --trials 50 --timeout 7200
    """

    try:
        # Load and validate configuration
        logger.info(f"Loading benchmark configuration from: {config}")

        config_data = _load_config(config)

        # Validate the final configuration
        benchmark_config = BenchmarkConfigModel(**config_data)

        # Find test images
        image_paths = benchmark_config.get_image_paths()
        if not image_paths:
            typer.echo(
                f"âŒ No test images found. Please check your test images configuration. ``{benchmark_config.test_images}``"
            )
            raise typer.Exit(1)

        logger.info(f"Found {len(image_paths)} test images for benchmarking")

        # Create output directory
        output_path = Path(benchmark_config.output.directory)
        output_path.mkdir(parents=True, exist_ok=True)

        benchmark_pipeline = BenchmarkPipeline.from_config(benchmark_config)

        # Run benchmarking
        typer.echo("ðŸš€ Starting detection pipeline benchmarking...")
        typer.echo(
            f"ðŸ“Š Configuration: {benchmark_config.execution.n_trials} trials, "
            f"{benchmark_config.execution.timeout}s timeout, "
            f"{benchmark_config.execution.direction} direction"
        )
        typer.echo(f"ðŸ–¼ï¸  Test images: {len(image_paths)} images")
        typer.echo(f"ðŸ“ Output directory: {output_path}")

        # Execute the benchmark
        benchmark_pipeline.run(
            n_trials=benchmark_config.execution.n_trials,
            timeout=benchmark_config.execution.timeout,
            direction=benchmark_config.execution.direction,
        )

        # Save results if requested
        if benchmark_config.output.save_results:
            _save_benchmark_results(benchmark_pipeline, benchmark_config, output_path)

        typer.echo("âœ… Benchmarking completed successfully!")

    except FileNotFoundError as e:
        typer.echo(f"âŒ Configuration file not found: {e}")
        raise typer.Exit(1)
    except yaml.YAMLError as e:
        typer.echo(f"âŒ Invalid YAML configuration: {e}")
        raise typer.Exit(1)
    except ValueError as e:
        typer.echo(f"âŒ Configuration validation error: {e}")
        raise typer.Exit(1)
    except Exception as e:
        logger.error(f"Unexpected error during benchmarking: {e}")
        typer.echo(f"âŒ Benchmarking failed: {e}")
        raise typer.Exit(1)


def _load_config(config_path: str) -> dict:
    """Load configuration from YAML file."""
    config_file = Path(config_path)
    if not config_file.exists():
        raise FileNotFoundError(f"Configuration file not found: {config_path}")

    with open(config_file, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


if __name__ == "__main__":
    app()
